<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="shortcut icon" href="/notas-de-aprendizaje/favicon.ico" type="image/x-icon"> <link rel="stylesheet" href="/notas-de-aprendizaje/assets/css/just-the-docs-default.css"> <script type="text/javascript" src="/notas-de-aprendizaje/assets/js/vendor/lunr.min.js"></script> <script type="text/javascript" src="/notas-de-aprendizaje/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.7.1 --> <title>MapReduce: Simplified Data Processing on Large Clusters | Notas</title> <meta name="generator" content="Jekyll v3.9.0" /> <meta property="og:title" content="MapReduce: Simplified Data Processing on Large Clusters" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="Notas de aprendizaje Santiago Rodriguez Morales" /> <meta property="og:description" content="Notas de aprendizaje Santiago Rodriguez Morales" /> <meta property="og:site_name" content="Notas" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:title" content="MapReduce: Simplified Data Processing on Large Clusters" /> <script type="application/ld+json"> {"@type":"WebPage","description":"Notas de aprendizaje Santiago Rodriguez Morales","url":"/notas-de-aprendizaje/papers/map-reduce/","headline":"MapReduce: Simplified Data Processing on Large Clusters","@context":"https://schema.org"}</script> <!-- End Jekyll SEO tag --> </head> <body> <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header"> <a href="/notas-de-aprendizaje/" class="site-title lh-tight"> Notas </a> <a href="#" id="menu-button" class="site-button"> <svg viewBox="0 0 24 24" class="icon"><use xlink:href="#svg-menu"></use></svg> </a> </div> <nav role="navigation" aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/notas-de-aprendizaje/articles/" class="nav-list-link">Articles</a><ul class="nav-list "></ul></li><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/notas-de-aprendizaje/books/" class="nav-list-link">Books</a><ul class="nav-list "></ul></li><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/notas-de-aprendizaje/talks/" class="nav-list-link">Talks</a><ul class="nav-list "></ul></li><li class="nav-list-item active"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="/notas-de-aprendizaje/papers/" class="nav-list-link">Papers</a><ul class="nav-list "></ul></li></ul> </nav> <footer class="site-footer"> This site uses <a href="https://github.com/pmarsceill/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll. </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search Notas" aria-label="Search Notas" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> <nav aria-label="Auxiliary" class="aux-nav"> <ul class="aux-nav-list"> <li class="aux-nav-list-item"> <a href="//github.com/sanrm/notas-de-aprendizaje" class="site-button" target="_blank" rel="noopener noreferrer" > Notas de aprendizaje en GitHub </a> </li> </ul> </nav> </div> <div id="main-content-wrap" class="main-content-wrap"> <nav aria-label="Breadcrumb" class="breadcrumb-nav"> <ol class="breadcrumb-nav-list"> <li class="breadcrumb-nav-list-item"><a href="/notas-de-aprendizaje/papers/">Papers</a></li> <li class="breadcrumb-nav-list-item"><span>MapReduce: Simplified Data Processing on Large Clusters</span></li> </ol> </nav> <div id="main-content" class="main-content" role="main"> <h1 id="mapreduce-simplified-data-processing-on-large-clusters"> <a href="#mapreduce-simplified-data-processing-on-large-clusters" class="anchor-heading" aria-labelledby="mapreduce-simplified-data-processing-on-large-clusters"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> <a href="https://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf">MapReduce: Simplified Data Processing on Large Clusters</a> </h1> <p>MapReduce is a programming model and an associated implementation for processing and generating large data sets. Users specify a <em>map</em> function that processes a key/value pair to generate a set of intermediate key/value pairs, and a <em>reduce</em> function that merges all intermediate values associated with the same intermediate key.</p> <p>Programs written in this functional style are automatically parallelised and executed on a large cluster of commodity machines. The run-time system takes care of the details of partitioning the input data, scheduling the program’s execution across a set of machines, handling machine failures, and managing the required inter-machine communication. This allows programmers without any experience with parallel and distributed systems to easily utilise the resources of a large distributed system.</p> <h2 id="introduction"> <a href="#introduction" class="anchor-heading" aria-labelledby="introduction"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Introduction </h2> <p>The abstraction is inspired by the <em>map</em> and <em>reduce</em> primitives present in Lisp and many other functional languages. Map and reduce operations allows easy parallelisation at the same time that re-execution serves as the primary mechanism for fault-tolerance.</p> <h2 id="programming-model"> <a href="#programming-model" class="anchor-heading" aria-labelledby="programming-model"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Programming model </h2> <p>The computation takes a set of <em>input</em> key/value pairs, and produces a set of <em>output</em> key/value pairs. The user of the MapReduce library expresses the computations as two functions: <em>Map</em> and <em>Reduce</em>.</p> <p><em>Map</em>, written by the user, takes an input pair and produces a set of <em>intermediate</em> key/value pairs. The MapReduce library groups together all intermediate values associated with the same intermediate Key <em>I</em> and passes them to the <em>Reduce</em> function.</p> <p>The <em>Reduce</em> function, also written by the user, accepts and intermediary key <em>I</em> and a set of values for that key. It merges together these values to form a possibly smaller set of values. Typically just zero or one output value is produced per <em>Reduce</em> invocation.</p> <h3 id="usage-exmples"> <a href="#usage-exmples" class="anchor-heading" aria-labelledby="usage-exmples"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Usage exmples </h3> <ul> <li>Distributed Grep: The map function emits a line if it matches a supplied pattern. The reduce function is an identity function that just copies the supplied intermediate data to the output.</li> <li>Count of URL access frequency: The map function processes logs of a web page requests and outputs <code class="language-plaintext highlighter-rouge">&lt;URL, 1&gt;</code>. The reduce function adds together all values for the same URL and emits a <code class="language-plaintext highlighter-rouge">&lt;URL, total count&gt;</code> pair.</li> <li>Distributed sort: The map functions extracts the key from each record, and emits a <code class="language-plaintext highlighter-rouge">&lt;key, record&gt;</code> pair. The reduce function emits all pairs unchanged.</li> </ul> <h2 id="implementation"> <a href="#implementation" class="anchor-heading" aria-labelledby="implementation"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Implementation </h2> <p>One implementation may be suitable for a small shared-memory machine, another for a large NUMA multi-processor, and yet another for an even larger collection of networked machines.</p> <h3 id="execution-overview"> <a href="#execution-overview" class="anchor-heading" aria-labelledby="execution-overview"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Execution overview </h3> <p>The <em>Map</em> invocations are distributed across multiple machines by automatically partitioning the input data into a set of <em>M splits</em>. The input splits can be processed in parallel by different machines. <em>Reduce</em> invocations are distributed by partitioning the intermediate key space into <em>R</em> pieces using a partitioning function. The number of partitions (<em>R</em>) and the partitioning function are specified by the user.</p> <p>Overall flow:</p> <ol> <li>The MapReduce library in the user program <strong>splits the input files into <em>M</em> pieces</strong> typically 16MB per piece. It then starts up many copies of the program on a cluster of machines.</li> <li>One of the copies of the program is special, the master. The rest are workers that are assigned work by the master. There are <em>M</em> map tasks and <em>R</em> reduce tasks to assign. <strong>The master picks idle workers and assigns each one a map task or reduce task.</strong></li> <li>A worker who is assigned a map task reads the contents of the corresponding input split. It <strong>parses key/value pairs out of the input data and passes each pair to the user-defined <em>Map</em></strong> function. The intermediate key/value pairs produced by the <em>Map</em> function are buffered in memory.</li> <li>Periodically, the <strong>buffered pairs are written to local disk</strong>, partitioned into <em>R</em> regions by the partitioning function. The locations of these buffered pairs on the local disk are passed back to the master, who is responsible for forwarding these locations to the reduce workers.</li> <li>When a <strong>reduce worker</strong> is notified by the master about these locations, it <strong>uses remote procedure calls to read the buffered data from the local disks of the map workers</strong>. When a reduce worker has read all intermediate data, it sorts it by the intermediate keys so that all occurrences of the same key are grouped together.</li> <li>The <strong>reduce worker</strong> iterates over the sorted intermediate data and <strong>for each unique intermediate key encountered, it passes the key and the corresponding set of intermediate values to the user’s <em>Reduce</em> function</strong>. The output of the <em>Reduce</em> function is appended to a final output file for this reduce partition.</li> <li>When all map tasks and reduce tasks have been completed, the master wakes up the user program. At this point the MapReduce call in the user program returns back to the user code.</li> </ol> <p>After successful completion, the output of the MapReduce execution is available in the <em>R</em> output files (one per reduce task, with the file names as specified by the user). Users usually don’t need to combine these <em>R</em> output files into one file, they can either use another MapReduce call or use a distributed application to process them.</p> <h3 id="master-data-structures"> <a href="#master-data-structures" class="anchor-heading" aria-labelledby="master-data-structures"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Master data structures </h3> <p>For each map task and reduce task, master stores the state (<em>idle</em>, <em>in-progress</em>, or <em>completed</em>) and the identity of the worker machine.</p> <p>For each completed map task, the master stores the locations and sizes of the <em>R</em> intermediate file regions produced by the map task. Updates to this location and size information are received as map tasks are compelted. The information is pushed incrementally to workers that have <em>in-progress</em> reduce tasks.</p> <h3 id="fault-tolerance"> <a href="#fault-tolerance" class="anchor-heading" aria-labelledby="fault-tolerance"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Fault tolerance </h3> <h4 id="worker-failure"> <a href="#worker-failure" class="anchor-heading" aria-labelledby="worker-failure"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Worker failure </h4> <p>The master pings every worker periodically. If no response is received from a worker in a certain amount of time, the master marks the worker as failed. Any map tasks completed by the worker are reset back to their initial <em>idle</em> state, and therefore become eligible for scheduling on other workers. Similarly, any map task or reduce task in progress on a failed worker is also reset to <em>idle</em> and becomes eligible for rescheduling.</p> <p>Completed map tasks are re-executed on failure because their output is stored on the local disks of the failed machine and is therefore inaccessible. Completed reduce tass do not need to be re-executed since their output is stored in a global file system.</p> <p>When a map task is executed first by worker <em>A</em>, and later executed by worker <em>B</em> (because <em>A</em> failed), all workers executing reduce tasks are notified of the re-execution. Any reduce task that has not already read the data from worker <em>A</em> will read the data from worker <em>B</em>.</p> <p>The MapReduce master simply re-executes the work done by unreachable worker machines and continues to make forward progress.</p> <h4 id="master-failure"> <a href="#master-failure" class="anchor-heading" aria-labelledby="master-failure"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Master failure </h4> <p>It’s easy to make the master write periodic checkpoints of the master data structures. If the master task dies, a new copy can be started from the last checkpointed state. Current implementation aborts the MapReduce computation if the master fails.</p> <h4 id="semantics-in-the-presence-of-failures"> <a href="#semantics-in-the-presence-of-failures" class="anchor-heading" aria-labelledby="semantics-in-the-presence-of-failures"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Semantics in the presence of failures </h4> <p>The vast majority of <em>map</em> and <em>reduce</em> operators are deterministic, and the fact that the semantics are equivalent to a sequential execution in this case makes it very easy for programmers to reason about their program’s behaviour.</p> <h3 id="localty"> <a href="#localty" class="anchor-heading" aria-labelledby="localty"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Localty </h3> <p>Network bandwith can be conserved by taking advantage of the fact that the input data (managed by GFS) is stored on the local disks of the machine that make up the cluster. Most input data is read locally and consumes no network bandwidth.</p> <h3 id="task-granularity"> <a href="#task-granularity" class="anchor-heading" aria-labelledby="task-granularity"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Task granularity </h3> <p>The map phase is subdivided into <em>M</em> pieces and reduce phase is divided into <em>R</em> Pieces. Having each worker perform many different tasks improves dynamic load balancing and also speeds up recovery when a worker fails.</p> <h3 id="backup-tasks"> <a href="#backup-tasks" class="anchor-heading" aria-labelledby="backup-tasks"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Backup tasks </h3> <p>One of the common causes that lengthens the total time taken for a MapReduce operation is a “straggler”, a machine that takes an unusually long time to complete one of the last few map or reduce tasks in the computation.</p> <p>There is a general mechanism to alleviate the problem of stragglers. When a MapReduce operation is close to completion, the master schedules backup executions of the remaining <em>in-progress</em> tasks. The task is marked as completed whenever either the primary or the backup execution completes. A distributed sorting program can take up to 44% longer without the backup task mechanism.</p> <h2 id="refinement"> <a href="#refinement" class="anchor-heading" aria-labelledby="refinement"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Refinement </h2> <h3 id="partitioning-function"> <a href="#partitioning-function" class="anchor-heading" aria-labelledby="partitioning-function"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Partitioning function </h3> <p>Users of MapReduce specify the number of reduce task/output files that they desire (<em>R</em>). A default partitioning function is provided that uses hashing (peg: <code class="language-plaintext highlighter-rouge">hash(key) mod R</code>), which tends to result in fairly well-balanced partitions. In some cases, it is useful to partition data by some other function of the key, for example sometimes the output keys are URLs, and is convenient to have a single host end up in the same output file. A partitioning function can be provided to MapReduce, for example <code class="language-plaintext highlighter-rouge">hash(Hostname(urlkey)) mod R</code>.</p> <h3 id="ordering-guarantees"> <a href="#ordering-guarantees" class="anchor-heading" aria-labelledby="ordering-guarantees"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Ordering guarantees </h3> <p>Within a given partition, the intermediate key/value pairs are guaranteed to be processed in increasing key order, which makes it easy to generate a sorted output file per partition.</p> <h3 id="combiner-function"> <a href="#combiner-function" class="anchor-heading" aria-labelledby="combiner-function"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Combiner function </h3> <p>MapReduce allows the user to specify a <em>Combiner</em> function that does partial merging of the data before it is sent over the network.</p> <p>The <em>Combiner</em> function is executed on each machine that performs a map task. The difference between a reduce function and a combiner function is how the MapReduce library handles the output of the function. The output of a reduce function is written to the final output file. The output of a combiner function is written to an intermediate field that will be sent to a reduce task.</p> <h3 id="input-and-output-types"> <a href="#input-and-output-types" class="anchor-heading" aria-labelledby="input-and-output-types"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Input and output types </h3> <p>“Text” mode input treats each line as a key/value pair: the key is the offset in the file and the value is the contents of the line. Another common supported format stores a sequence of a key/value pairs sorted by key.</p> <p>Users can add support for a new input type by providing an implementation of a simple <em>reader</em> interface, though most users just use one of a small number of predefined input types.</p> <p>In a similar fashion, a set of output types for producing data in different formats is supported.</p> <h3 id="side-effects"> <a href="#side-effects" class="anchor-heading" aria-labelledby="side-effects"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Side-effects </h3> <p>Users of MapReduce may find convenient to produce auxiliary files. The application writer can make such side-effects atomic and idempotent.</p> <h3 id="skipping-bad-records"> <a href="#skipping-bad-records" class="anchor-heading" aria-labelledby="skipping-bad-records"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Skipping bad records </h3> <p>Sometimes there are bugs in user code that can cause the <em>Map</em> or <em>Reduce</em> functions to crash deterministically on certain records, which prevents the whole MapReduce operation from completing.</p> <p>There is an optional mode of execution where the MapReduce library detects which records cause deterministic crashes and skips these records in order to make forward progress. Each worker process installs a signal handler that catches segmentation violations and bus errors. Before invoking a user <em>Map</em> or <em>Reduce</em> operation, the MapReduce library stores the sequence number of the argument in a variable. The signal handler sends a “last gasp” UDP packet that contains the sequence number to the master. When the master has seen more than one failure on a particular record, it indicates that the record should be skipped.</p> <h3 id="local-execution"> <a href="#local-execution" class="anchor-heading" aria-labelledby="local-execution"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Local execution </h3> <p>To help facilitate debugging, profiling, and small-scale testing, there is an alternative implementation of the MapReduce library that sequentially executes all of the work for a MapReduce operation on the local machine.</p> <h3 id="status-information"> <a href="#status-information" class="anchor-heading" aria-labelledby="status-information"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Status information </h3> <p>The master runs an internal HTTP server and exports a set of status pages for human consumption.</p> <h3 id="counters"> <a href="#counters" class="anchor-heading" aria-labelledby="counters"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Counters </h3> <p>The MapReduce library provides a counter facility to count occurrences of various events, like the count of total number of words processed, documents indexed, etc.</p> <p>The counter values from individual worker machines are periodically propagated to the master. The master aggregates the counter values from successful map and reduce tasks and returns them to the user code when the MapReduce operation is completed. The master eliminates the effects of duplicate executions of the same map or reduce task to avoid double counting.</p> <h2 id="experience"> <a href="#experience" class="anchor-heading" aria-labelledby="experience"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Experience </h2> <p>MapReduce has been used at Google for a wide range of domains including:</p> <ul> <li>Large-scale machine learning problems.</li> <li>Clustering problems for the Google News and Froggle products.</li> <li>Extraction of data used to produce reports of popular queries.</li> <li>Extraction of the properties of web pages for new experiments and products.</li> <li>Large-scale graph computations.</li> </ul> <p>MapReduce has been so successful because it makes it possible to write a simple program and run it efficiently on a thousand machines int he course of half an hour, greatly speeding up the development and prototyping cycle. It allows programmers who have no experience with distributed and/or parallel systems to exploit large amounts of resources easily.</p> <h3 id="large-scale-indexing"> <a href="#large-scale-indexing" class="anchor-heading" aria-labelledby="large-scale-indexing"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Large-scale indexing </h3> <p>Probably the most significant use of MapReduce is the rewrite of the production indexing system that produces the data structures used for the Google web search service. Using MapReduce has provided several benefits:</p> <ul> <li>The indexing code is simpler, smaller, and easier to understand, because the code that deals with fault tolerance, distribution, and parallelisation is hidden within the MapReduce library.</li> <li>The performance of the MapReduce library is good enough that it can keep conceptually unrelated computations separate, instead of mixing them together to avoid extra passes over the data.</li> <li>The indexing process has become much easier to operate, because most of the problems caused by machine failures, slow machines, and networking hiccups are dealt with automatically by the MapReduce library without operator intervention.</li> </ul> <h2 id="related-work"> <a href="#related-work" class="anchor-heading" aria-labelledby="related-work"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Related work </h2> <p>MapReduce exploits a restricted programming model to parallelise the user program automatically and to provide transparent fault-tolerance.</p> <p>By restricting the programming model, the MapReduce framework is able to partition the problem into a larger number of fine-grained tasks. These tasks are dynamically scheduled on available workers so that faster worker process more tasks. The restricted programming model also allows to schedule redundant execution of tasks near the end of the job which greatly reduces completion time in the presence of non-uniformities.</p> <h2 id="conclusions"> <a href="#conclusions" class="anchor-heading" aria-labelledby="conclusions"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Conclusions </h2> <p>The success of MapReduce is attributed to:</p> <ol> <li>The model is easy to use, even for programmers without experience with parallel and distributed systems, since it hides the details of parallelisation, fault-tolerance, locality optimisation, and load balancing.</li> <li>A large variety of problems are easily expressible as MapReduce computations.</li> <li>There is an implementation of MapReduce that scales to large clusters of machines compromising thousand of machines.</li> </ol> <p>Some learnings:</p> <ol> <li>Restricting the programming model makes it easy to parallelise and distribute computations and to make such computations fault-tolerance.</li> <li>Network bandwidth is a scarce resource. A number of optimisations in the system have been done towards reducing the amount of data sent across the network.</li> <li>Redundant execution can be used to reduce the impact of slow machines, and to handle machine failures and data loss.</li> </ol> </div> </div> <div class="search-overlay"></div> </div> </body> </html>
